diff --git a/brian2/devices/cpp_standalone/device.py b/brian2/devices/cpp_standalone/device.py
index e57fd61..3528356 100644
--- a/brian2/devices/cpp_standalone/device.py
+++ b/brian2/devices/cpp_standalone/device.py
@@ -991,6 +991,7 @@ def run(self, directory, with_output, run_args):
                 with open('results/last_run_info.txt', 'r') as f:
                     last_run_info = f.read()
                 self._last_run_time, self._last_run_completed_fraction = map(float, last_run_info.split())
+        print("INFO _last_run_time = {} s".format(self._last_run_time))
 
         # Make sure that integration did not create NaN or very large values
         owners = [var.owner for var in self.arrays]
diff --git a/brian2/synapses/synapses.py b/brian2/synapses/synapses.py
index e1bb8d8..e1b9adb 100644
--- a/brian2/synapses/synapses.py
+++ b/brian2/synapses/synapses.py
@@ -281,7 +281,8 @@ def update_abstract_code(self, run_namespace=None, level=0):
             self.abstract_code = ''
 
         self.abstract_code += self.code + '\n'
-        self.abstract_code += 'lastupdate = t\n'
+        if self.synapses.need_lastupdate:
+            self.abstract_code += 'lastupdate = t\n'
 
     @device_override('synaptic_pathway_before_run')
     def before_run(self, run_namespace):
@@ -737,8 +738,11 @@ def __init__(self, source, target=None, model=None, on_pre=None,
                 raise SyntaxError('"%s" is a reserved name that cannot be '
                                   'used as a variable name.' % name)
 
-        # Add the lastupdate variable, needed for event-driven updates
-        model = model + Equations('lastupdate : second')
+        # Check if a `lastupdate` variable is needed
+        self.need_lastupdate = self._check_lastupdate(model, on_pre, on_post)
+        if self.need_lastupdate:
+            model = model + Equations('lastupdate : second')
+
         # Add the "multisynaptic index", if desired
         self.multisynaptic_index = multisynaptic_index
         if multisynaptic_index is not None:
@@ -928,6 +932,32 @@ def __getitem__(self, item):
         indices = self.indices[item]
         return SynapticSubgroup(self, indices)
 
+    def _check_lastupdate(self, model, on_pre, on_post):
+        # check if `lastupdate` is used as identifier in synapse model equations
+        if 'lastupdate' in model.identifiers:
+            return True
+        # removing lastupdate breaks GeNN (TODO)
+        if get_device().__class__.__name__ == 'GeNNDevice':
+            return True
+        # check if we have `event-driven` dynamics
+        for eq in model.itervalues():
+            if 'event-driven' in eq.flags:
+                return True
+        # get all pathway event update codes
+        pathway_codes = []
+        for argument in [on_pre, on_post]:
+            if isinstance(argument, basestring):
+                pathway_codes.append(argument)
+            elif isinstance(argument, collections.Mapping):
+                for value in argument.itervalues():
+                    pathway_codes.append(value)
+        # check if lastupdate is needed for event update code
+        for code in pathway_codes:
+            # TODO: this also catches e.g. 'mylastupdate', use some brian parser!
+            if 'lastupdate' in code:
+                return True
+        return False
+
     def _set_delay(self, delay, with_unit):
         if 'pre' not in self._synaptic_updaters:
             raise AttributeError("Synapses do not have a 'pre' pathway, "
diff --git a/brian2/tests/features/base.py b/brian2/tests/features/base.py
index 2fc47aa..8d8c0be 100644
--- a/brian2/tests/features/base.py
+++ b/brian2/tests/features/base.py
@@ -226,8 +226,10 @@ def after_run(self):
                             with_output=False)
     
     
-def results(configuration, feature, n=None, maximum_run_time=1e7*brian2.second):
-    tempfilename = tempfile.mktemp('exception')
+def results(configuration, feature, n=None, maximum_run_time=1e7*brian2.second,
+           profile_only_active=False):
+    tempfilename = 'my_file_1'#tempfile.mktemp('exception')
+    tempfilename_net_obj = 'my_file_2'#tempfile.mktemp('network_objects')
     if n is None:
         init_args = ''
     else:
@@ -235,9 +237,9 @@ def results(configuration, feature, n=None, maximum_run_time=1e7*brian2.second):
     code_string = '''
 __file__ = '{fname}'
 import brian2
-from {config_module} import {config_name}
+import {config_module}
 from {feature_module} import {feature_name}
-configuration = {config_name}()
+configuration = {config_module}.{config_name}()
 feature = {feature_name}({init_args})
 import warnings, traceback, pickle, sys, os, time
 warnings.simplefilter('ignore')
@@ -246,6 +248,12 @@ def results(configuration, feature, n=None, maximum_run_time=1e7*brian2.second):
     configuration.before_run()
     brian2.device._set_maximum_run_time({maximum_run_time})
     feature.run()
+    if {prof_active}:
+        code_objects = []
+        for obj in brian2.magic_network.objects:
+            if obj.active:
+                for codeobj in obj._code_objects:
+                    code_objects.append(codeobj.name)
     configuration.after_run()
     results = feature.results()
     run_time = time.time()-start_time
@@ -256,39 +264,72 @@ def results(configuration, feature, n=None, maximum_run_time=1e7*brian2.second):
             pass
     lrcf = configuration.get_last_run_completed_fraction()
     run_time = run_time/lrcf
-    prof_info = brian2.magic_network.profiling_info
     new_prof_info = []
-    for n, t in prof_info:
-        new_prof_info.append((n, t/lrcf))
+    try:
+        prof_info = brian2.magic_network.profiling_info
+        for n, t in prof_info:
+            new_prof_info.append((n, t/lrcf))
+    except ValueError:
+        pass
     f = open(r'{tempfname}', 'wb')
     pickle.dump((None, results, run_time, new_prof_info), f, -1)
     f.close()
+    if {prof_active}:
+        f2 = open(r'{tempfname_net_obj}', 'wb')
+        pickle.dump(code_objects, f2, -1)
+        f2.close()
 except Exception, ex:
     #traceback.print_exc(file=sys.stdout)
     tb = traceback.format_exc()
     f = open(r'{tempfname}', 'wb')
     pickle.dump((tb, ex, 0.0, []), f, -1)
     f.close()
+    if {prof_active}:
+        f2 = open(r'{tempfname_net_obj}', 'wb')
+        pickle.dump([], f2, -1)
+        f2.close()
     '''.format(config_module=configuration.__module__,
                config_name=configuration.__name__,
                feature_module=feature.__module__,
                feature_name=feature.__name__,
                tempfname=tempfilename,
+               tempfname_net_obj=tempfilename_net_obj,
                fname=__file__,
                init_args=init_args,
                maximum_run_time=float(maximum_run_time),
+               prof_active=str(profile_only_active)
                )
     args = [sys.executable, '-c',
             code_string]
+    if hasattr(configuration, 'git_commit') and configuration.git_commit is not None:
+        # checkout the commit specified in the DynamicConfigCreator
+        configuration.git_checkout()
+        # checkout the original version of the module defining the feature
+        configuration.git_checkout_feature(feature.__module__)
+        configuration.git_checkout_feature(configuration.__module__)
     # Run the example in a new process and make sure that stdout gets
     # redirected into the capture plugin
     p = subprocess.Popen(args, stdout=subprocess.PIPE,
                          stderr=subprocess.PIPE)
     stdout, stderr = p.communicate()
-    #sys.stdout.write(stdout)
-    #sys.stderr.write(stderr)
+    if p.returncode:
+        sys.stdout.write(stdout)
+        sys.stderr.write(stderr)
     with open(tempfilename, 'rb') as f:
         tb, res, runtime, profiling_info = pickle.load(f)
+    if isinstance(res, Exception):
+        tb = stdout + '\n' + stderr + '\n' + tb
+    if profile_only_active:
+        with open(tempfilename_net_obj, 'rb') as f:
+            network_codeobjects = pickle.load(f)
+        profiling_info = [(codeobj, time)
+                              for (codeobj, time) in profiling_info
+                              if codeobj in network_codeobjects]
+    if hasattr(configuration, 'git_commit') and configuration.git_commit is not None:
+        # reset the current changes before checking out original commit
+        configuration.git_reset()
+        # check out the original commit
+        configuration.git_checkout(reverse=True)
     return tb, res, runtime, profiling_info
     
 
@@ -477,7 +518,7 @@ def __str__(self):
 
 
 def run_speed_tests(configurations=None, speed_tests=None, run_twice=True, verbose=True,
-                    n_slice=slice(None), maximum_run_time=1e7*brian2.second):
+                    n_slice=slice(None), maximum_run_time=1e7*brian2.second, profile_only_active=True):
     if configurations is None:
         # some configurations to attempt to import
         try:
@@ -495,15 +536,22 @@ def run_speed_tests(configurations=None, speed_tests=None, run_twice=True, verbo
     full_results = {}
     tag_results = defaultdict(lambda:defaultdict(list))
     for ft in speed_tests:
+        traceback = {}
+        brian_stdouts = {}
+        result = {}
         if verbose:
             print ft.fullname()+': ',
+            sys.stdout.flush()
         for n in ft.n_range[n_slice]:
             if verbose:
                 print 'n=%d [' % n,
+                sys.stdout.flush()
             for configuration in configurations:
                 sym = '.'
+                brian_stdout = ''
                 for _ in xrange(1+int(run_twice)):
-                    tb, res, runtime, prof_info = results(configuration, ft, n, maximum_run_time=maximum_run_time)
+                    tb, res, runtime, prof_info = results(configuration, ft, n, maximum_run_time=maximum_run_time,
+                                                          profile_only_active=profile_only_active)
                 if isinstance(res, Exception):
                     if isinstance(res, NotImplementedError):
                         sym = 'N'
@@ -512,8 +560,24 @@ def run_speed_tests(configurations=None, speed_tests=None, run_twice=True, verbo
                     if configuration is DefaultConfiguration:
                         raise res
                     runtime = numpy.NAN
+                    proj_dir = ''
+                    if configuration.name.startswith("CUDA"):
+                        proj_dir = 'cuda_standalone'
+                    elif configuration.name.startswith("CPP"):
+                        proj_dir = 'cpp_standalone'
+                    elif configuration.name.startswith("GeNN"):
+                        proj_dir = 'GeNNWorkspace'
+                    stdout_file = os.path.join(os.getcwd(), proj_dir, 'results/stdout.txt')
+                    if os.path.exists(stdout_file):
+                        brian_stdout = open(stdout_file, 'r').read()
+                    else:
+                        brian_stdout = 'no stdout file found, cwd = {}'.format(stdout_file)
                 sys.stdout.write(sym)
+                sys.stdout.flush()
                 full_results[configuration.name, ft.fullname(), n, 'All'] = runtime
+                traceback[configuration.name, n] = tb
+                brian_stdouts[configuration.name, n] = brian_stdout
+                result[configuration.name, n] = res
                 suffixtime = defaultdict(float)
                 overheadstime = float(runtime)
                 for codeobjname, proftime in prof_info:
@@ -528,8 +592,14 @@ def run_speed_tests(configurations=None, speed_tests=None, run_twice=True, verbo
                 full_results[configuration.name, ft.fullname(), n, 'Overheads'] = overheadstime
             if verbose:
                 print ']',
+                sys.stdout.flush()
         if verbose:
             print
+            for n in ft.n_range[n_slice]:
+                for conf in configurations:
+                    if isinstance(result[conf.name, n], Exception):
+                        print("\nTRACEBACK {} N={}\n{}\n{}\n\n".format(conf.name, n, brian_stdouts[conf.name, n],
+                                                                       traceback[conf.name, n]))
         
     return SpeedTestResults(full_results, configurations, speed_tests)
 
@@ -550,7 +620,7 @@ def get_codeobjsuffixes(self, fullname):
         confignames, fullnames, n, codeobjsuffixes  = zip(*L)
         return set(codeobjsuffixes)
 
-    def plot_all_tests(self, relative=False, profiling_minimum=1.0):
+    def plot_all_tests(self, relative=False, profiling_minimum=1.0, print_relative=False):
         if relative and profiling_minimum<1:
             raise ValueError("Cannot use relative plots with profiling")
         import pylab
@@ -581,13 +651,22 @@ def plot_all_tests(self, relative=False, profiling_minimum=1.0):
                         if float(thistime/runtime)>=profiling_minimum:
                             skip = False
                         runtimes.append(thistime)
+                        #overheadstime = self.full_results.get((configname, fullname, n, 'Overheads'), numpy.nan)
+                        #if (profiling_minimum<1 and  overheadstime == runtime:
+                        #    skip = True
                     if skip:
                         continue
                     runtimes = numpy.array(runtimes)
-                    if relative:
+                    if relative or print_relative:
                         if baseline is None:
                             baseline = runtimes
+                    if relative:
                         runtimes = baseline/runtimes
+                    if print_relative:
+                        rel = baseline/runtimes
+                        for ni, n in enumerate(ns):
+                            print("INFO relative performance for {ft} N={n} {conf}: {factor}".format(
+                                ft=fullname, n=n, conf=config.name, factor=rel[ni]))
                     if suffix=='All':
                         lw = 2
                         label = configname
@@ -627,6 +706,7 @@ def plot_all_tests(self, relative=False, profiling_minimum=1.0):
                 pylab.gca().set_xscale('log')
             if st.time_axis_log:
                 pylab.gca().set_yscale('log')
+            pylab.grid(True, which='both')
 
 # Code below auto generates restructured text tables, copied from:
 # http://stackoverflow.com/questions/11347505/what-are-some-approaches-to-outputting-a-python-data-structure-to-restructuredte
diff --git a/brian2/tests/features/speed.py b/brian2/tests/features/speed.py
index 75f3410..9e58abd 100644
--- a/brian2/tests/features/speed.py
+++ b/brian2/tests/features/speed.py
@@ -22,7 +22,7 @@ class LinearNeuronsOnly(SpeedTest):
     category = "Neurons only"
     name = "Linear 1D"
     tags = ["Neurons"]
-    n_range = [10, 100, 1000, 10000, 100000, 1000000]
+    n_range = [10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 261015625]  #fail: 262031250
     n_label = 'Num neurons'
 
     # configuration options
@@ -41,7 +41,7 @@ class HHNeuronsOnly(SpeedTest):
     category = "Neurons only"
     name = "Hodgkin-Huxley"
     tags = ["Neurons"]
-    n_range = [10, 100, 1000, 10000, 100000]
+    n_range = [10, 100, 1000, 10000, 100000, 1000000, 10000000, 102750000]  #fail: 103125000
     n_label = 'Num neurons'
 
     # configuration options
@@ -85,7 +85,7 @@ class CUBAFixedConnectivity(SpeedTest):
     category = "Full examples"
     name = "CUBA fixed connectivity"
     tags = ["Neurons", "Synapses", "SpikeMonitor"]
-    n_range = [10, 100, 1000, 10000, 100000]
+    n_range = [10, 100, 1000, 10000, 100000, 1000000, 3546875]  #fail: 3562500
     n_label = 'Num neurons'
 
     # configuration options
@@ -131,7 +131,7 @@ class COBAHHFixedConnectivity(SpeedTest):
     category = "Full examples"
     name = "COBAHH fixed connectivity"
     tags = ["Neurons", "Synapses", "SpikeMonitor"]
-    n_range = [100, 500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000]
+    n_range = [100, 500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000, 3781250]  #fail: 3812500
     n_label = 'Num neurons'
 
     # configuration options
@@ -254,7 +254,7 @@ def run(self):
 class SynapsesOnly(object):
     category = "Synapses only"
     tags = ["Synapses"]
-    n_range = [10, 100, 1000, 10000]
+    n_range = [10, 100, 1000, 10000, 100000, 1000000]
     n_label = 'Num neurons'
     duration = 1 * second
     # memory usage will be approximately p**2*rate*dt*N**2*bytes_per_synapse/1024**3 GB
@@ -281,7 +281,7 @@ class VerySparseMediumRateSynapsesOnly(SynapsesOnly, SpeedTest):
     name = "Very sparse, medium rate (10s duration)"
     rate = 10 * Hz
     p = 0.02
-    n_range = [10, 100, 1000, 10000, 100000]  # weave max CPU time should be about 20s
+    n_range = [10, 100, 1000, 10000, 100000, 500000, 1000000, 3875000]  #fail: 3906250  # weave max CPU time should be about 20s
     duration = 10 * second
 
 
@@ -289,21 +289,21 @@ class SparseMediumRateSynapsesOnly(SynapsesOnly, SpeedTest):
     name = "Sparse, medium rate (1s duration)"
     rate = 10 * Hz
     p = 0.2
-    n_range = [10, 100, 1000, 10000, 100000]  # weave max CPU time should be about 5m
+    n_range = [10, 100, 1000, 10000, 100000, 500000, 1000000, 1234375]  #fail: 1242187  # weave max CPU time should be about 5m
 
 
 class DenseMediumRateSynapsesOnly(SynapsesOnly, SpeedTest):
     name = "Dense, medium rate (1s duration)"
     rate = 10 * Hz
     p = 1.0
-    n_range = [10, 100, 1000, 10000, 40000]  # weave max CPU time should be about 4m
+    n_range = [10, 100, 1000, 10000, 100000, 500000, 546875]  #fail: 554687  # weave max CPU time should be about 4m
 
 
 class SparseLowRateSynapsesOnly(SynapsesOnly, SpeedTest):
     name = "Sparse, low rate (10s duration)"
     rate = 1 * Hz
     p = 0.2
-    n_range = [10, 100, 1000, 10000, 100000]  # weave max CPU time should be about 20s
+    n_range = [10, 100, 1000, 10000, 100000, 500000, 1000000, 3875000]  #fail: 3906250  # weave max CPU time should be about 20s
     duration = 10 * second
 
 
@@ -311,7 +311,7 @@ class SparseHighRateSynapsesOnly(SynapsesOnly, SpeedTest):
     name = "Sparse, high rate (1s duration)"
     rate = 100 * Hz
     p = 0.2
-    n_range = [10, 100, 1000, 10000]  # weave max CPU time should be about 5m
+    n_range = [10, 100, 1000, 10000, 100000, 387500]  #fail: 393750  # weave max CPU time should be about 5m
 
 
 if __name__ == '__main__':
diff --git a/brian2/tests/test_synapses.py b/brian2/tests/test_synapses.py
index 9063e3d..26d8530 100644
--- a/brian2/tests/test_synapses.py
+++ b/brian2/tests/test_synapses.py
@@ -1481,7 +1481,7 @@ def test_pre_post_variables():
     for var in ['v_pre', 'v', 'v_post', 'w', 'w_post', 'x',
                 'N_pre', 'N_post', 'N_incoming', 'N_outgoing',
                 'i', 'j',
-                't', 'lastupdate', 'dt']:
+                't', 'dt']:
         assert var in S.variables
     # Check that postsynaptic variables without suffix refer to the correct
     # variable
@@ -1495,6 +1495,27 @@ def test_pre_post_variables():
 
 
 @attr('codegen-independent')
+def test_lastupdate_variable():
+    G = NeuronGroup(10, 'v : 1', threshold='False')
+    S1 = Synapses(G, G, 'x = lastupdate : second')
+    S2 = Synapses(G, G, 'x : 1', on_pre='x += lastupdate')
+    S3 = Synapses(G, G, 'x : 1', on_post='x += lastupdate')
+    on_pre = {'path1': 'x+=1',
+              'path2': 'x += lastupdate'}
+    S3 = Synapses(G, G, 'x : 1', on_pre=on_pre)
+
+    for syn in [S1, S2, S3]:
+        assert 'lastupdate' in syn.variables
+
+    S1_ = Synapses(G, G, 'x : 1')
+    S2_ = Synapses(G, G, 'x : 1', on_pre='x += 1')
+    S3_ = Synapses(G, G, 'x : 1', on_post='x += 1')
+
+    for syn in [S1_, S2_, S3_]:
+        assert not 'lastupdate' in syn.variables
+
+
+@attr('codegen-independent')
 def test_variables_by_owner():
     # Test the `variables_by_owner` convenience function
     G = NeuronGroup(10, 'v : 1')
@@ -2434,6 +2455,7 @@ def test_synapse_generator_range_noint():
     test_delays_pathways_subgroups()
     test_pre_before_post()
     test_pre_post_simple()
+    test_lastupdate_variable()
     test_transmission_simple()
     test_transmission_custom_event()
     test_invalid_custom_event()
